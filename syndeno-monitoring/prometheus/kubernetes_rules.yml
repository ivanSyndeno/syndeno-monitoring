groups:
- name: alert.rules
  rules:
  - alert: KubernetesNodeReady
    expr: kube_node_status_condition{condition="Ready",status="true"} == 0
    for: 10m
    labels:
      severity: critical
      category: kubernetes
      client: "{{ $labels.cluster }}"
    annotations:
      summary: "{{ $labels.cluster }} - Kubernetes Node ready (instance {{ $labels.instance }})"
      description: "{{ $labels.cluster }} - Node {{ $labels.node }} has been unready for a long time\n"

  - alert: KubernetesMemoryPressure
    expr: kube_node_status_condition{condition="MemoryPressure",status="true"} == 1
    for: 2m
    labels:
      severity: critical
      category: memory
      client: "{{ $labels.cluster }}"
    annotations:
      summary: "{{ $labels.cluster }} - {{ $labels.endpoint }} - Kubernetes memory pressure (instance {{ $labels.instance }})"
      description: "{{ $labels.cluster }} - {{ $labels.node }} has MemoryPressure condition\n"

  - alert: KubernetesDiskPressure
    expr: kube_node_status_condition{condition="DiskPressure",status="true"} == 1
    for: 2m
    labels:
      severity: critical
      category: memory
      client: "{{ $labels.cluster }}"
    annotations:
      summary: "{{ $labels.cluster }} - {{ $labels.endpoint }} - Kubernetes disk pressure (instance {{ $labels.instance }})"
      description: "{{ $labels.cluster }} - {{ $labels.node }} has DiskPressure condition\n"  

  # - alert: KubernetesOutOfCapacity
  #   expr: sum by (node) ((kube_pod_status_phase{phase="Running"} == 1) + on(uid) group_left(node) (0 * kube_pod_info{pod_template_hash=""})) / sum by (node) (kube_node_status_allocatable{resource="pods"}) * 100 > 90
  #   for: 2m
  #   labels:
  #     severity: warning
  #     client: "{{ $labels.cluster }}"
  #   annotations:
  #     summary: "{{ $labels.cluster }} - {{ $labels.endpoint }} - Kubernetes out of capacity (instance {{ $labels.instance }})"
  #     description: "{{ $labels.cluster }} - {{ $labels.node }} is out of capacity\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"

  - alert: KubernetesPersistentvolumeclaimPending
    expr: kube_persistentvolumeclaim_status_phase{phase="Pending"} == 1
    for: 2m
    labels:
      severity: warning
      category: memory
      client: "{{ $labels.cluster }}"
    annotations:
      summary: "{{ $labels.cluster }} - {{ $labels.endpoint }} - Kubernetes PersistentVolumeClaim pending (instance {{ $labels.instance }})"
      description: "{{ $labels.cluster }} - PersistentVolumeClaim {{ $labels.namespace }}/{{ $labels.persistentvolumeclaim }} is pending\n"   

  # - alert: KubernetesVolumeFullInFourDays
  #   expr: predict_linear(kubelet_volume_stats_available_bytes[6h], 4 * 24 * 3600) < 0
  #   for: 0m
  #   labels:
  #     severity: critical
  #   annotations:
  #     summary: Kubernetes Volume full in four days (instance {{ $labels.instance }})
  #     description: "{{ $labels.namespace }}/{{ $labels.persistentvolumeclaim }} is expected to fill up within four days. Currently {{ $value | humanize }}% is available.\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"   

  - alert: KubernetesStatefulsetDown
    expr: (kube_statefulset_status_replicas_ready / kube_statefulset_status_replicas_current) == 0
    for: 1m
    labels:
      severity: critical
      category: kubernetes
      client: "{{ $labels.cluster }}"
    annotations:
      summary: "{{ $labels.cluster }} - {{ $labels.endpoint }} - Kubernetes StatefulSet down (instance {{ $labels.instance }})"
      description: "{{ $labels.cluster }} - A StatefulSet went down\n"

  - alert: KubernetesPodNotHealthy
    expr: sum_over_time(kube_pod_container_status_running[5m]) == 0
    for: 5m
    labels:
      severity: critical
      category: kubernetesPod
      client: "{{ $labels.cluster }}"
    annotations:
      summary: "{{ $labels.cluster }} - {{ $labels.endpoint }} - Kubernetes Pod not healthy (instance {{ $labels.instance }})"
      description: "{{ $labels.cluster }} - Node {{ $labels.pod }}- Pod has been in a non-ready state for longer than 15 minutes.\n"   

  - alert: KubernetesPodCrashLooping
    expr: increase(kube_pod_container_status_restarts_total[1m]) > 3
    for: 2m
    labels:
      severity: warning
      category: kubernetesPod
      client: "{{ $labels.cluster }}"
    annotations:
      summary: "{{ $labels.cluster }} - {{ $labels.endpoint }} - Kubernetes pod crash looping (instance {{ $labels.instance }})"
      description: "{{ $labels.cluster }} - Pod {{ $labels.pod }} is crash looping\n"   

  - alert: KubernetesReplicassetMismatch
    expr: kube_replicaset_spec_replicas != kube_replicaset_status_ready_replicas
    for: 10m
    labels:
      severity: warning
      category: kubernetes
      client: "{{ $labels.cluster }}"
    annotations:
      summary: "{{ $labels.cluster }} - {{ $labels.endpoint }} - Kubernetes ReplicasSet mismatch (instance {{ $labels.instance }})"
      description: "{{ $labels.cluster }} - Deployment Replicas mismatch\n"

  - alert: KubernetesDeploymentReplicasMismatch
    expr: kube_deployment_spec_replicas != kube_deployment_status_replicas_available
    for: 10m
    labels:
      severity: warning
      category: kubernetesDeployment
      client: "{{ $labels.cluster }}"
    annotations:
      summary: "{{ $labels.cluster }} - { $labels.endpoint }} - Kubernetes Deployment replicas mismatch (instance {{ $labels.instance }})"
      description: "{{ $labels.cluster }} - Deployment Replicas mismatch\n"      

  - alert: KubernetesStatefulsetReplicasMismatch
    expr: kube_statefulset_status_replicas_ready != kube_statefulset_status_replicas
    for: 10m
    labels:
      severity: warning
      category: kubernetesReplicas
      client: "{{ $labels.cluster }}"
    annotations:
      summary: "{{ $labels.cluster }} - Kubernetes StatefulSet replicas mismatch (instance {{ $labels.instance }})"
      description: "A StatefulSet does not match the expected number of replicas.\n"

  - alert: KubernetesDaemonsetRolloutStuck
    expr: kube_daemonset_status_number_ready / kube_daemonset_status_desired_number_scheduled * 100 < 100 or kube_daemonset_status_desired_number_scheduled - kube_daemonset_status_current_number_scheduled > 0
    for: 10m
    labels:
      severity: warning
      category: kubernetes
      client: "{{ $labels.cluster }}"
    annotations:
      summary: "{{ $labels.cluster }} - {{ $labels.endpoint }} - Kubernetes DaemonSet rollout stuck (instance {{ $labels.instance }})"
      description: "{{ $labels.cluster }} - Some Pods of DaemonSet are not scheduled or not ready\n"

  #- alert: Prometheus||NO||Datos
  #  expr: up == 0
  #  for: 1m
  #  labels:
  #    severity: critical
  #  annotations:
  #    summary: "Prometheus is not up"
  #    description: "Prometheus is down or unreachable."


  #- alert: VelocidadCpuu
  #  expr: 1
  #  labels:
  #    severity: critical
  #  annotations:
  #    summary: "La velocidad de la CPU es muy lenta"
  #    description: "La velocidad del cluster: {{ $labels.cluster }} Del job: {{ $labels.job }} es demasiado LENTA valor: {{ $value }} por mÃ¡s>"
  #    app_link: "https://monitoring.gc.syndeno.net/d/q8cAoXjdd/syndeno-monitoring-panel-alarmas-v2?orgId=1&from=1713943080584&to=171394668058>"

